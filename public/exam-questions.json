{
  "exam": {
    "id": "exam-panaversity-l2",
    "title": "Fundamentals of Agentic AI",
    "description": "Complete your examination carefully. Each answer is final - no back button available.",
    "examType": "Panaversity Exam",
    "totalQuestions": 150,
    "duration": 170,
    "passingPercentage": 70,
    "instructions": [
      "Read each question carefully before answering",
      "Each answer is final - no back button available",
      "Your exam will auto-submit when time runs out",
      "Anti-cheating measures are active",
      "Exam must be taken in fullscreen mode - exiting fullscreen will auto-submit your exam"
    ]
  },
  "questions": [
    {
      "id": 1,
      "question": "What is the primary purpose of the OpenAI Agents Python SDK?",
      "options": [
        "To provide a REST API for OpenAI models",
        "To create lightweight, powerful multi-agent workflows",
        "To replace the OpenAI Python client library",
        "To build mobile applications with AI"
      ],
      "correctAnswer": 1,
      "explanation": "The OpenAI Agents Python SDK is designed to create lightweight, powerful multi-agent workflows, making it easier to build complex agent systems."
    },
    {
      "id": 2,
      "question": "How many core primitives does the OpenAI Agents SDK have?",
      "options": ["Two", "Three", "Four", "Five"],
      "correctAnswer": 2,
      "explanation": "The SDK operates on four core primitives: Agents, Handoffs, Guardrails, and Sessions."
    },
    {
      "id": 3,
      "question": "Which SDK did the OpenAI Agents Python SDK evolve from?",
      "options": ["LangChain", "Swarm framework", "AutoGPT", "LlamaIndex"],
      "correctAnswer": 1,
      "explanation": "The SDK evolved from the experimental Swarm framework released in October 2024, incorporating critical production features."
    },
    {
      "id": 4,
      "question": "What is the default model used by the OpenAI Agents SDK?",
      "options": ["gpt-3.5-turbo", "gpt-4", "gpt-4.1", "gpt-5"],
      "correctAnswer": 2,
      "explanation": "The default model is gpt-4.1, chosen for its balance of predictability and low latency in agentic workflows."
    },
    {
      "id": 5,
      "question": "What is the minimum Python version required to install the OpenAI Agents SDK?",
      "options": ["Python 3.7", "Python 3.8", "Python 3.9", "Python 3.10"],
      "correctAnswer": 2,
      "explanation": "Installing the SDK requires Python 3.9 or newer with the openai v2.x package."
    },
    {
      "id": 6,
      "question": "Which class orchestrates agent execution in the SDK?",
      "options": ["Agent", "Runner", "Session", "Handoff"],
      "correctAnswer": 1,
      "explanation": "The Runner class orchestrates agent execution through methods like run(), run_sync(), and run_streamed()."
    },
    {
      "id": 7,
      "question": "What happens when a handoff occurs in the SDK?",
      "options": [
        "The original agent continues running in parallel",
        "The conversation history is cleared",
        "The new agent receives complete conversation history and assumes control",
        "Both agents share control equally"
      ],
      "correctAnswer": 2,
      "explanation": "When a handoff occurs, the new agent receives the entire conversation history and assumes control, with the original agent never returning to the loop."
    },
    {
      "id": 8,
      "question": "What are the two fundamental multi-agent patterns supported by the SDK?",
      "options": [
        "Sequential and Parallel",
        "Manager Pattern and Handoffs Pattern",
        "Centralized and Distributed",
        "Synchronous and Asynchronous"
      ],
      "correctAnswer": 1,
      "explanation": "The SDK supports the Manager Pattern (agents-as-tools with central orchestration) and the Handoffs Pattern (decentralized peer delegation)."
    },
    {
      "id": 9,
      "question": "When do input guardrails execute?",
      "options": [
        "After the agent completes its response",
        "During every agent turn",
        "On initial user input, in parallel with the first agent turn",
        "Only during handoffs"
      ],
      "correctAnswer": 2,
      "explanation": "Input guardrails execute on initial user input simultaneously with the first agent turn, allowing fast rejection of problematic requests before expensive model calls complete."
    },
    {
      "id": 10,
      "question": "What does the output_type parameter do?",
      "options": [
        "Specifies the file format for logs",
        "Defines the agent's communication protocol",
        "Transforms agents from text generators into structured data producers",
        "Sets the output encoding format"
      ],
      "correctAnswer": 2,
      "explanation": "The output_type parameter transforms agents from text generators into structured data producers by specifying a Pydantic model, dataclass, TypedDict, or list type."
    },
    {
      "id": 11,
      "question": "Which decorator is used to transform a Python function into an agent tool?",
      "options": ["@tool", "@agent_tool", "@function_tool", "@create_tool"],
      "correctAnswer": 2,
      "explanation": "The @function_tool decorator transforms any Python function into an agent tool with automatic schema generation."
    },
    {
      "id": 12,
      "question": "What is the purpose of Sessions in the SDK?",
      "options": [
        "To manage API authentication",
        "To eliminate the manual burden of managing conversation history",
        "To control agent execution order",
        "To handle error logging"
      ],
      "correctAnswer": 1,
      "explanation": "Sessions eliminate the manual burden of managing conversation history across turns, automatically loading and storing conversation history."
    },
    {
      "id": 13,
      "question": "Which session implementation is recommended for development?",
      "options": [
        "SQLAlchemySession",
        "OpenAIConversationsSession",
        "SQLiteSession",
        "EncryptedSession"
      ],
      "correctAnswer": 2,
      "explanation": "SQLiteSession is recommended for development, offering both in-memory and file-based modes for simple persistence."
    },
    {
      "id": 14,
      "question": "How many LLM providers does the SDK support through LiteLLM?",
      "options": ["10+", "50+", "100+", "200+"],
      "correctAnswer": 2,
      "explanation": "The SDK supports 100+ LLM providers through LiteLLM, including Anthropic Claude, Google Gemini, Azure, Bedrock, and Mistral."
    },
    {
      "id": 15,
      "question": "Is tracing enabled by default in the SDK?",
      "options": [
        "No, it must be manually enabled",
        "Yes, it is enabled by default",
        "Only in production mode",
        "Only for error cases"
      ],
      "correctAnswer": 1,
      "explanation": "Tracing is enabled by default and sends execution data to OpenAI's platform for visualization and debugging at platform.openai.com/traces."
    },
    {
      "id": 16,
      "question": "What does the max_turns parameter prevent?",
      "options": [
        "Multiple users from accessing the agent",
        "Excessive API costs",
        "Infinite loops in agent execution",
        "Concurrent tool executions"
      ],
      "correctAnswer": 2,
      "explanation": "The max_turns parameter prevents infinite loops by raising MaxTurnsExceeded when exceeded, with typical values ranging from 5 to 20+."
    },
    {
      "id": 17,
      "question": "What does MCP stand for in the SDK?",
      "options": [
        "Multi-Component Protocol",
        "Model Context Protocol",
        "Message Communication Protocol",
        "Management Control Panel"
      ],
      "correctAnswer": 1,
      "explanation": "MCP stands for Model Context Protocol, which provides a standardized way to connect agents to external tools and services."
    },
    {
      "id": 18,
      "question": "Which temperature range is typically recommended for factual tasks?",
      "options": ["0.7-1.0", "1.0-1.5", "0.1-0.3", "1.5-2.0"],
      "correctAnswer": 2,
      "explanation": "Factual tasks typically use temperature values of 0.1-0.3 for more deterministic outputs, while creative tasks use 0.7-1.0."
    },
    {
      "id": 19,
      "question": "What method is used to create variations of existing agents?",
      "options": ["duplicate()", "copy()", "clone()", "replicate()"],
      "correctAnswer": 2,
      "explanation": "The clone() method duplicates agents with modified properties using dataclasses.replace(), perfect for creating variations."
    },
    {
      "id": 20,
      "question": "Which hosted tool enables real-time web search capabilities?",
      "options": [
        "SearchTool",
        "WebSearchTool",
        "InternetSearchTool",
        "BrowserTool"
      ],
      "correctAnswer": 1,
      "explanation": "WebSearchTool provides real-time web search capabilities and is one of the hosted tools that run on LLM servers."
    },
    {
      "id": 21,
      "question": "What is the purpose of the RunContextWrapper?",
      "options": [
        "To wrap API responses",
        "To provide dependency injection for user data and state",
        "To handle error messages",
        "To manage concurrent executions"
      ],
      "correctAnswer": 1,
      "explanation": "The RunContextWrapper provides dependency injection, passing user data, API clients, and state seamlessly to every agent, tool, and lifecycle hook."
    },
    {
      "id": 22,
      "question": "Which API does the SDK recommend for OpenAI models?",
      "options": [
        "Chat Completions API",
        "Completions API",
        "Responses API",
        "Embeddings API"
      ],
      "correctAnswer": 2,
      "explanation": "The SDK works seamlessly with OpenAI's Responses API (recommended) and Chat Completions API, with Responses API being the recommended choice."
    },
    {
      "id": 23,
      "question": "What happens when a guardrail's tripwire is triggered?",
      "options": [
        "The agent continues with a warning",
        "Execution halts immediately with an exception",
        "The request is logged and forwarded",
        "The agent retries with different parameters"
      ],
      "correctAnswer": 1,
      "explanation": "When a guardrail's tripwire is triggered, execution halts immediately with InputGuardrailTripwireTriggered or OutputGuardrailTripwireTriggered exceptions."
    },
    {
      "id": 24,
      "question": "Which method converts a RunResult into input format for subsequent turns?",
      "options": [
        "convert_to_input()",
        "to_input_list()",
        "format_input()",
        "prepare_next_turn()"
      ],
      "correctAnswer": 1,
      "explanation": "The to_input_list() method converts the result into input format for subsequent turns when not using sessions."
    },
    {
      "id": 25,
      "question": "What does the agent.as_tool() method do?",
      "options": [
        "Converts tools into agents",
        "Transforms agents into tools for hierarchical orchestration",
        "Creates a new agent instance",
        "Validates agent configuration"
      ],
      "correctAnswer": 1,
      "explanation": "The agent.as_tool() method transforms agents into tools to create hierarchical orchestration without handoffs, allowing the orchestrator to retain control."
    },
    {
      "id": 26,
      "question": "Which session implementation provides transparent encryption?",
      "options": [
        "SQLiteSession",
        "SQLAlchemySession",
        "EncryptedSession",
        "OpenAIConversationsSession"
      ],
      "correctAnswer": 2,
      "explanation": "EncryptedSession wraps other sessions with transparent Fernet encryption and TTL-based expiration for secure storage."
    },
    {
      "id": 27,
      "question": "What is the purpose of parallel_tool_calls parameter?",
      "options": [
        "To run multiple agents simultaneously",
        "To enable or disable multiple simultaneous tool invocations",
        "To parallelize guardrail checks",
        "To handle concurrent user requests"
      ],
      "correctAnswer": 1,
      "explanation": "The parallel_tool_calls parameter enables or disables multiple simultaneous tool invocations, reducing latency when tools are independent."
    },
    {
      "id": 28,
      "question": "Which GPT-5 model setting controls reasoning depth?",
      "options": [
        "reasoning.effort",
        "thinking.depth",
        "analysis.level",
        "processing.intensity"
      ],
      "correctAnswer": 0,
      "explanation": "The reasoning.effort parameter accepts levels like 'minimal', 'low', 'medium', and 'high' for GPT-5 models, controlling reasoning depth and speed."
    },
    {
      "id": 29,
      "question": "What does the FileSearchTool provide?",
      "options": [
        "Local file system browsing",
        "Vector store retrieval capabilities",
        "Text file editing",
        "File compression utilities"
      ],
      "correctAnswer": 1,
      "explanation": "FileSearchTool is a hosted tool that provides vector store retrieval capabilities for semantic search over documents."
    },
    {
      "id": 30,
      "question": "Which method is used to retrieve recent conversation history from a session?",
      "options": [
        "fetch_items()",
        "retrieve_history()",
        "get_items()",
        "load_messages()"
      ],
      "correctAnswer": 2,
      "explanation": "The get_items(limit=N) method retrieves recent conversation history from a session, useful for displaying conversation context."
    },
    {
      "id": 31,
      "question": "What is the purpose of input filters in handoffs?",
      "options": [
        "To validate input data types",
        "To control what conversation context passes to the next agent",
        "To compress conversation history",
        "To encrypt sensitive information"
      ],
      "correctAnswer": 1,
      "explanation": "Input filters control what conversation context passes to the next agent during handoffs, useful for privacy, reducing context size, or focusing attention."
    },
    {
      "id": 32,
      "question": "Which exception is raised when max_turns is exceeded?",
      "options": [
        "TurnLimitException",
        "MaxTurnsExceeded",
        "AgentLoopError",
        "ExecutionLimitReached"
      ],
      "correctAnswer": 1,
      "explanation": "The MaxTurnsExceeded exception is raised when the agent loop exceeds the max_turns limit, typically from infinite reasoning loops."
    },
    {
      "id": 33,
      "question": "What command is used to install the SDK with LiteLLM support?",
      "options": [
        "pip install openai-agents-litellm",
        "pip install openai-agents --with-litellm",
        "pip install \"openai-agents[litellm]\"",
        "pip install openai-agents && pip install litellm"
      ],
      "correctAnswer": 2,
      "explanation": "To install with LiteLLM support for 100+ providers, use: pip install \"openai-agents[litellm]\"."
    },
    {
      "id": 34,
      "question": "When do output guardrails execute?",
      "options": [
        "Before the agent starts processing",
        "During every tool call",
        "Only when the agent is the last in the workflow",
        "At random intervals for security"
      ],
      "correctAnswer": 2,
      "explanation": "Output guardrails validate final agent responses before delivery, executing only if the agent is the last in the workflow."
    },
    {
      "id": 35,
      "question": "What does the CodeInterpreterTool enable?",
      "options": [
        "JavaScript execution in the browser",
        "Sandboxed Python execution and data analysis",
        "Code translation between languages",
        "Syntax highlighting for code snippets"
      ],
      "correctAnswer": 1,
      "explanation": "CodeInterpreterTool is a hosted tool that provides sandboxed Python execution and data analysis capabilities."
    },
    {
      "id": 36,
      "question": "Which context manager is used to create custom spans for tracing?",
      "options": [
        "trace_span()",
        "custom_span()",
        "create_span()",
        "measure_span()"
      ],
      "correctAnswer": 1,
      "explanation": "The custom_span(name, data) context manager enables detailed workflow instrumentation by measuring specific operations like database queries or API calls."
    },
    {
      "id": 37,
      "question": "What is the default reasoning.effort level for GPT-5 models in the SDK?",
      "options": ["minimal", "low", "medium", "high"],
      "correctAnswer": 1,
      "explanation": "The SDK automatically applies sensible defaults with reasoning.effort='low' for GPT-5 reasoning models."
    },
    {
      "id": 38,
      "question": "Which pattern is ideal when specialized agents should maintain domain ownership?",
      "options": [
        "Manager Pattern",
        "Handoffs Pattern",
        "Sequential Pattern",
        "Parallel Pattern"
      ],
      "correctAnswer": 1,
      "explanation": "The Handoffs Pattern is ideal when specialized agents should maintain domain ownership and continue natural conversation flow."
    },
    {
      "id": 39,
      "question": "What method is used to remove the most recent item from a session?",
      "options": [
        "remove_last()",
        "delete_item()",
        "pop_item()",
        "clear_last()"
      ],
      "correctAnswer": 2,
      "explanation": "The pop_item() method removes and returns the most recent item from a session, useful for correction flows."
    },
    {
      "id": 40,
      "question": "Which hosted tool enables UI automation?",
      "options": ["AutomationTool", "ComputerTool", "UITool", "BrowserTool"],
      "correctAnswer": 1,
      "explanation": "ComputerTool is a hosted tool that provides UI automation capabilities."
    },
    {
      "id": 41,
      "question": "What does the tool_use_behavior parameter control?",
      "options": [
        "Which tools are available to the agent",
        "How tool outputs are processed",
        "The order of tool execution",
        "Tool permission levels"
      ],
      "correctAnswer": 1,
      "explanation": "The tool_use_behavior parameter controls how tool outputs are processed, with options like 'run_llm_again' or 'stop_on_first_tool'."
    },
    {
      "id": 42,
      "question": "Which event type in streaming provides token-by-token deltas?",
      "options": [
        "TokenStreamEvent",
        "RawResponsesStreamEvent",
        "DeltaStreamEvent",
        "TextStreamEvent"
      ],
      "correctAnswer": 1,
      "explanation": "RawResponsesStreamEvent contains token-by-token deltas from the LLM, perfect for displaying text as it generates."
    },
    {
      "id": 43,
      "question": "What is the purpose of the hooks parameter in Agent configuration?",
      "options": [
        "To integrate external APIs",
        "To define callbacks for lifecycle events",
        "To manage error handling",
        "To configure logging levels"
      ],
      "correctAnswer": 1,
      "explanation": "The hooks parameter accepts AgentHooks or RunHooks instances defining callbacks for lifecycle events like on_agent_start, on_llm_start, etc."
    },
    {
      "id": 44,
      "question": "Which session method wipes all conversation history?",
      "options": [
        "reset_session()",
        "delete_all()",
        "clear_session()",
        "remove_history()"
      ],
      "correctAnswer": 2,
      "explanation": "The clear_session() method wipes all history from a session, appropriate for new topics or privacy concerns."
    },
    {
      "id": 45,
      "question": "What does SQLAlchemySession support?",
      "options": [
        "Only SQLite databases",
        "Only PostgreSQL databases",
        "PostgreSQL, MySQL, and SQLite with async drivers",
        "Only in-memory databases"
      ],
      "correctAnswer": 2,
      "explanation": "SQLAlchemySession integrates with production databases supporting PostgreSQL, MySQL, and SQLite with async operations."
    },
    {
      "id": 46,
      "question": "Which function sets the default OpenAI API key programmatically?",
      "options": [
        "configure_api_key()",
        "set_api_key()",
        "set_default_openai_key()",
        "init_openai_key()"
      ],
      "correctAnswer": 2,
      "explanation": "The set_default_openai_key('sk-...') function sets the API key programmatically, though it must occur before any SDK usage."
    },
    {
      "id": 47,
      "question": "What does the ImageGenerationTool integrate with?",
      "options": ["Midjourney", "Stable Diffusion", "DALL-E", "Adobe Firefly"],
      "correctAnswer": 2,
      "explanation": "ImageGenerationTool is a hosted tool that integrates with DALL-E for AI image generation capabilities."
    },
    {
      "id": 48,
      "question": "Which property contains all items generated during execution in a RunResult?",
      "options": [
        "execution_items",
        "generated_items",
        "new_items",
        "output_items"
      ],
      "correctAnswer": 2,
      "explanation": "The new_items property lists all items generated during execution, including messages, tool calls, tool outputs, and handoff events."
    },
    {
      "id": 49,
      "question": "What is the purpose of the is_enabled parameter in tools?",
      "options": [
        "To activate tool permissions",
        "To dynamically enable or disable tools at runtime",
        "To check tool compatibility",
        "To validate tool schemas"
      ],
      "correctAnswer": 1,
      "explanation": "The is_enabled parameter allows tools to be dynamically enabled or disabled at runtime based on context or conditions."
    },
    {
      "id": 50,
      "question": "Which docstring formats does the SDK support for tool parameter descriptions?",
      "options": [
        "Only Google format",
        "Only reStructuredText",
        "Google, Sphinx, and NumPy formats",
        "Only plain text"
      ],
      "correctAnswer": 2,
      "explanation": "The SDK uses griffe to parse docstrings, supporting Google, Sphinx, and NumPy formats for extracting parameter descriptions."
    },
    {
      "id": 51,
      "question": "What does the OpenAIConversationsSession do?",
      "options": [
        "Stores conversations in a local database",
        "Leverages OpenAI's hosted conversation management",
        "Encrypts all conversation data",
        "Compresses conversation history"
      ],
      "correctAnswer": 1,
      "explanation": "OpenAIConversationsSession leverages OpenAI's hosted conversation management, eliminating local storage entirely."
    },
    {
      "id": 52,
      "question": "Which parameter limits the output length of model responses?",
      "options": [
        "output_limit",
        "response_length",
        "max_tokens",
        "token_limit"
      ],
      "correctAnswer": 2,
      "explanation": "The max_tokens parameter in ModelSettings limits output length, useful for cost control or latency optimization."
    },
    {
      "id": 53,
      "question": "What is the primary difference between handoffs and agents-as-tools?",
      "options": [
        "Handoffs are faster than agents-as-tools",
        "Handoffs transfer control completely; agents-as-tools return to caller",
        "Agents-as-tools require more configuration",
        "Handoffs can only work with OpenAI models"
      ],
      "correctAnswer": 1,
      "explanation": "Handoffs transfer control completely to the new agent, while agents-as-tools return to the caller after execution, maintaining orchestrator control."
    },
    {
      "id": 54,
      "question": "Which method provides type-safe extraction of final output?",
      "options": [
        "extract_output()",
        "get_output_as()",
        "final_output_as()",
        "cast_output()"
      ],
      "correctAnswer": 2,
      "explanation": "The final_output_as(Type) method provides type-safe extraction, casting final_output to the specified type with validation."
    },
    {
      "id": 55,
      "question": "What does the frequency_penalty parameter do?",
      "options": [
        "Increases response frequency",
        "Reduces token repetition",
        "Controls API call frequency",
        "Adjusts sampling frequency"
      ],
      "correctAnswer": 1,
      "explanation": "The frequency_penalty parameter (range -2.0 to 2.0) reduces token repetition in model outputs."
    },
    {
      "id": 56,
      "question": "Which MCP transport type spawns local subprocesses?",
      "options": [
        "MCPServerHttp",
        "MCPServerLocal",
        "MCPServerStdio",
        "MCPServerProcess"
      ],
      "correctAnswer": 2,
      "explanation": "MCPServerStdio spawns local subprocesses communicating via stdin/stdout, perfect for command-line MCP servers."
    },
    {
      "id": 57,
      "question": "What is the purpose of the presence_penalty parameter?",
      "options": [
        "Controls API rate limiting",
        "Manages user presence detection",
        "Encourages topic diversity",
        "Reduces latency"
      ],
      "correctAnswer": 2,
      "explanation": "The presence_penalty parameter (range -2.0 to 2.0) encourages topic diversity in model outputs."
    },
    {
      "id": 58,
      "question": "Which stream event signals agent changes during handoffs?",
      "options": [
        "HandoffStreamEvent",
        "AgentUpdatedStreamEvent",
        "AgentChangeEvent",
        "TransferStreamEvent"
      ],
      "correctAnswer": 1,
      "explanation": "AgentUpdatedStreamEvent signals agent changes during handoffs, enabling real-time workflow visualization."
    },
    {
      "id": 59,
      "question": "What does the tool_choice parameter value 'required' mean?",
      "options": [
        "The tool must be installed",
        "The LLM must use a tool",
        "The tool requires authentication",
        "The tool needs approval"
      ],
      "correctAnswer": 1,
      "explanation": "When tool_choice is set to 'required', the LLM must use a tool rather than responding with text only."
    },
    {
      "id": 60,
      "question": "Which function enables verbose logging for debugging?",
      "options": [
        "set_debug_mode()",
        "enable_logging()",
        "enable_verbose_stdout_logging()",
        "configure_logging()"
      ],
      "correctAnswer": 2,
      "explanation": "The enable_verbose_stdout_logging() convenience function enables verbose logging output for debugging."
    },
    {
      "id": 61,
      "question": "What does the Runner.run_sync() method do?",
      "options": [
        "Synchronizes multiple agents",
        "Wraps async run() for synchronous contexts",
        "Runs tools synchronously",
        "Syncs conversation history"
      ],
      "correctAnswer": 1,
      "explanation": "Runner.run_sync() wraps the async run() method for synchronous contexts like simple scripts, but cannot be used in existing event loops."
    },
    {
      "id": 62,
      "question": "Which property identifies which agent produced the final output?",
      "options": [
        "output_agent",
        "final_agent",
        "last_agent",
        "responsible_agent"
      ],
      "correctAnswer": 2,
      "explanation": "The last_agent property identifies which agent produced the final output, critical in multi-agent workflows."
    },
    {
      "id": 63,
      "question": "What is the purpose of the on_handoff callback?",
      "options": [
        "To validate handoff permissions",
        "To execute when the handoff is invoked for side effects",
        "To compress handoff data",
        "To log all handoffs automatically"
      ],
      "correctAnswer": 1,
      "explanation": "The on_handoff callback executes when the handoff is invoked, receiving context and enabling side effects like logging or notifications."
    },
    {
      "id": 64,
      "question": "Which environment variable sets the default model globally?",
      "options": [
        "OPENAI_MODEL",
        "DEFAULT_MODEL",
        "OPENAI_DEFAULT_MODEL",
        "SDK_DEFAULT_MODEL"
      ],
      "correctAnswer": 2,
      "explanation": "The OPENAI_DEFAULT_MODEL environment variable sets a different default model globally, e.g., 'export OPENAI_DEFAULT_MODEL=gpt-5'."
    },
    {
      "id": 65,
      "question": "What does the HostedMCPTool run on?",
      "options": [
        "Local developer machines",
        "OpenAI's infrastructure",
        "Cloud serverless functions",
        "Edge computing nodes"
      ],
      "correctAnswer": 1,
      "explanation": "HostedMCPTool runs on OpenAI's infrastructure with tools listed and invoked without Python callbacks."
    },
    {
      "id": 66,
      "question": "Which method retrieves all tools including MCP tools from an agent?",
      "options": [
        "list_tools()",
        "get_tools()",
        "get_all_tools()",
        "fetch_tools()"
      ],
      "correctAnswer": 2,
      "explanation": "The get_all_tools() method retrieves all tools including MCP tools from an agent configuration."
    },
    {
      "id": 67,
      "question": "What is the range for the temperature parameter?",
      "options": ["0.0 to 1.0", "0.0 to 2.0", "0.0 to 5.0", "-1.0 to 1.0"],
      "correctAnswer": 1,
      "explanation": "Temperature ranges from 0.0 (deterministic) to 2.0 (highly random) for controlling response randomness."
    },
    {
      "id": 68,
      "question": "Which parameter customizes how handoffs appear to the LLM?",
      "options": [
        "handoff_name",
        "tool_name_override",
        "display_name",
        "llm_name"
      ],
      "correctAnswer": 1,
      "explanation": "The tool_name_override parameter customizes how the handoff appears to the LLM, improving routing accuracy."
    },
    {
      "id": 69,
      "question": "What does the verbosity parameter control in GPT-5 models?",
      "options": [
        "Logging detail",
        "Response length constraints",
        "Reasoning step visibility",
        "Token usage reporting"
      ],
      "correctAnswer": 1,
      "explanation": "The verbosity parameter ('low', 'medium', 'high') constrains response length in GPT-5 models."
    },
    {
      "id": 70,
      "question": "Which class provides complete control over LLM integration?",
      "options": ["CustomModel", "Model", "LLMIntegration", "ProviderModel"],
      "correctAnswer": 1,
      "explanation": "Direct Model implementation inheritance enables complete control over LLM integration by implementing the Model base class."
    },
    {
      "id": 71,
      "question": "What does AgentOutputSchema allow?",
      "options": [
        "Strict schema validation only",
        "Non-strict schemas that allow additional properties",
        "Schema versioning",
        "Schema inheritance"
      ],
      "correctAnswer": 1,
      "explanation": "AgentOutputSchema supports non-strict schemas that allow additional properties beyond those defined in the model."
    },
    {
      "id": 72,
      "question": "Which parameter adds custom attributes to traces?",
      "options": [
        "trace_attributes",
        "custom_metadata",
        "trace_metadata",
        "trace_tags"
      ],
      "correctAnswer": 2,
      "explanation": "The trace_metadata parameter in RunConfig adds custom attributes to traces for additional context."
    },
    {
      "id": 73,
      "question": "What does the LocalShellTool enable?",
      "options": [
        "Remote SSH access",
        "Command execution on the local system",
        "Shell script generation",
        "Terminal emulation"
      ],
      "correctAnswer": 1,
      "explanation": "LocalShellTool is a hosted tool that enables command execution on the local system."
    },
    {
      "id": 74,
      "question": "Which method is used to disable tracing globally?",
      "options": [
        "disable_tracing()",
        "set_tracing_disabled(True)",
        "turn_off_tracing()",
        "tracing_enable(False)"
      ],
      "correctAnswer": 1,
      "explanation": "The set_tracing_disabled(True) function disables tracing globally across all runs."
    },
    {
      "id": 75,
      "question": "What is the purpose of the strict_mode parameter in @function_tool?",
      "options": [
        "Enables strict error handling",
        "Enforces strict naming conventions",
        "Enables strict JSON validation",
        "Requires strict type annotations"
      ],
      "correctAnswer": 2,
      "explanation": "The strict_mode parameter in @function_tool enables strict JSON validation for tool parameters."
    },
    {
      "id": 76,
      "question": "Which property contains guardrail evaluation results in RunResult?",
      "options": [
        "guardrail_outputs",
        "validation_results",
        "input_guardrail_results and output_guardrail_results",
        "guardrail_checks"
      ],
      "correctAnswer": 2,
      "explanation": "The input_guardrail_results and output_guardrail_results properties contain guardrail evaluation results."
    },
    {
      "id": 77,
      "question": "What does the conversation_id parameter enable?",
      "options": [
        "Local conversation tracking",
        "OpenAI's server-side conversation management",
        "Conversation encryption",
        "Multi-user conversations"
      ],
      "correctAnswer": 1,
      "explanation": "The conversation_id parameter enables OpenAI's server-side conversation state management without local sessions."
    },
    {
      "id": 78,
      "question": "Which exception indicates SDK misuse such as invalid parameters?",
      "options": [
        "ConfigurationError",
        "UserError",
        "SDKException",
        "ParameterError"
      ],
      "correctAnswer": 1,
      "explanation": "UserError indicates SDK misuse such as invalid parameters or incorrect configuration."
    },
    {
      "id": 79,
      "question": "What does the custom_output_extractor function do in agents-as-tools?",
      "options": [
        "Validates tool outputs",
        "Transforms RunResult objects into tool outputs",
        "Extracts error messages",
        "Compresses output data"
      ],
      "correctAnswer": 1,
      "explanation": "The custom_output_extractor function transforms RunResult objects into tool outputs, useful for extracting specific data."
    },
    {
      "id": 80,
      "question": "Which session implementation is recommended for distributed deployments?",
      "options": [
        "SQLiteSession",
        "FileSession",
        "Redis-based sessions",
        "MemorySession"
      ],
      "correctAnswer": 2,
      "explanation": "Redis-based sessions are recommended for distributed deployments enabling horizontal scaling across multiple servers."
    },
    {
      "id": 81,
      "question": "What does the failure_error_function parameter do?",
      "options": [
        "Logs all failures automatically",
        "Enables custom error handling for tool failures",
        "Disables error reporting",
        "Sends error notifications"
      ],
      "correctAnswer": 1,
      "explanation": "The failure_error_function parameter enables custom error handling for tool failures, allowing custom error messages or logging."
    },
    {
      "id": 82,
      "question": "Which transport type is ideal for publicly accessible MCP servers?",
      "options": [
        "MCPServerStdio",
        "MCPServerSse",
        "HostedMCPTool",
        "MCPServerLocal"
      ],
      "correctAnswer": 2,
      "explanation": "HostedMCPTool is ideal for publicly accessible servers or OpenAI connectors, running entirely on OpenAI's infrastructure."
    },
    {
      "id": 83,
      "question": "What does the top_p parameter provide?",
      "options": [
        "Priority ordering",
        "Nucleus sampling as an alternative to temperature",
        "Top result filtering",
        "Probability threshold"
      ],
      "correctAnswer": 1,
      "explanation": "The top_p parameter (0.0-1.0) provides nucleus sampling as an alternative to temperature for controlling randomness."
    },
    {
      "id": 84,
      "question": "Which lifecycle hook executes when a tool starts?",
      "options": ["tool_started", "on_tool_start", "before_tool", "tool_begin"],
      "correctAnswer": 1,
      "explanation": "The on_tool_start hook executes when a tool starts, enabling logging and monitoring at tool execution points."
    },
    {
      "id": 85,
      "question": "What does the previous_response_id parameter enable?",
      "options": [
        "Response caching",
        "Response chaining where each turn links to the previous response",
        "Response versioning",
        "Response rollback"
      ],
      "correctAnswer": 1,
      "explanation": "The previous_response_id parameter enables response chaining where each turn explicitly links to the previous response."
    },
    {
      "id": 86,
      "question": "Which method fetches only MCP server tools from an agent?",
      "options": [
        "get_mcp_tools()",
        "fetch_mcp_tools()",
        "list_mcp_tools()",
        "retrieve_mcp_tools()"
      ],
      "correctAnswer": 0,
      "explanation": "The get_mcp_tools() method fetches only MCP server tools from an agent configuration."
    },
    {
      "id": 87,
      "question": "What does ModelBehaviorError indicate?",
      "options": [
        "Model not found",
        "Unexpected LLM behavior like malformed JSON",
        "Model rate limiting",
        "Model deprecation"
      ],
      "correctAnswer": 1,
      "explanation": "ModelBehaviorError covers unexpected LLM behavior like malformed JSON or invalid tool calls."
    },
    {
      "id": 88,
      "question": "Which parameter controls whether to include token usage statistics?",
      "options": [
        "track_usage",
        "include_usage",
        "usage_enabled",
        "count_tokens"
      ],
      "correctAnswer": 1,
      "explanation": "The include_usage parameter in ModelSettings controls whether to include token usage statistics, required for LiteLLM tracking."
    },
    {
      "id": 89,
      "question": "What is the purpose of the group_id in tracing?",
      "options": [
        "To group agents together",
        "To associate multiple conversations or traces",
        "To define user groups",
        "To organize tools by category"
      ],
      "correctAnswer": 1,
      "explanation": "The group_id in RunConfig associates multiple conversations or traces, for example, all traces in a chat thread."
    },
    {
      "id": 90,
      "question": "Which function configures a custom OpenAI client?",
      "options": [
        "configure_client()",
        "set_openai_client()",
        "set_default_openai_client()",
        "init_client()"
      ],
      "correctAnswer": 2,
      "explanation": "The set_default_openai_client() function accepts an AsyncOpenAI instance configured with custom parameters."
    },
    {
      "id": 91,
      "question": "What does the StopAtTools behavior do?",
      "options": [
        "Prevents all tool usage",
        "Stops at specific tools based on tool names",
        "Halts on tool errors",
        "Disables tool streaming"
      ],
      "correctAnswer": 1,
      "explanation": "StopAtTools(stop_at_tool_names=[...]) stops execution at specific tools, enabling sophisticated control flow."
    },
    {
      "id": 92,
      "question": "Which class is the base for all SDK exceptions?",
      "options": [
        "SDKException",
        "BaseException",
        "AgentsException",
        "RuntimeException"
      ],
      "correctAnswer": 2,
      "explanation": "AgentsException serves as the base class for all SDK exceptions, useful for catching any SDK-related error."
    },
    {
      "id": 93,
      "question": "What does the workflow_name parameter do in RunConfig?",
      "options": [
        "Names the agent workflow",
        "Enables logical grouping of traces",
        "Sets the execution strategy",
        "Defines the workflow version"
      ],
      "correctAnswer": 1,
      "explanation": "The workflow_name parameter in RunConfig enables logical grouping of traces for related operations."
    },
    {
      "id": 94,
      "question": "Which parameter enables caching of MCP tool discovery results?",
      "options": [
        "enable_cache",
        "cache_enabled",
        "cache_tools_list",
        "use_tool_cache"
      ],
      "correctAnswer": 2,
      "explanation": "The cache_tools_list=True parameter on MCP servers caches tool discovery results when tool lists change infrequently."
    },
    {
      "id": 95,
      "question": "What does the trace_include_sensitive_data parameter control?",
      "options": [
        "Encryption of trace data",
        "Whether to include LLM and tool inputs/outputs in traces",
        "Access permissions for traces",
        "Trace retention duration"
      ],
      "correctAnswer": 1,
      "explanation": "The trace_include_sensitive_data parameter controls whether to include LLM and tool inputs/outputs in traces."
    },
    {
      "id": 96,
      "question": "Which pattern uses a central orchestrator invoking specialists?",
      "options": [
        "Delegation Pattern",
        "Manager Pattern",
        "Coordinator Pattern",
        "Hub Pattern"
      ],
      "correctAnswer": 1,
      "explanation": "The Manager Pattern uses agents-as-tools where a central orchestrator invokes specialized sub-agents and retains conversation control."
    },
    {
      "id": 97,
      "question": "What does MCPServerSse use for communication?",
      "options": ["WebSockets", "HTTP polling", "Server-Sent Events", "gRPC"],
      "correctAnswer": 2,
      "explanation": "MCPServerSse uses Server-Sent Events (SSE) for real-time updates and communication."
    },
    {
      "id": 98,
      "question": "Which parameter accepts a Prompt object for external configuration?",
      "options": [
        "external_prompt",
        "prompt_config",
        "prompt",
        "dynamic_prompt"
      ],
      "correctAnswer": 2,
      "explanation": "The prompt parameter accepts a Prompt object or dynamic function for external prompt configuration with version control."
    },
    {
      "id": 99,
      "question": "What is returned by the stream_events() method?",
      "options": [
        "A list of events",
        "An async generator yielding event objects",
        "A JSON stream",
        "A callback function"
      ],
      "correctAnswer": 1,
      "explanation": "The stream_events() method returns an async generator yielding real-time event objects during execution."
    },
    {
      "id": 100,
      "question": "Which feature enables approval workflows in MCP servers?",
      "options": [
        "approval_enabled",
        "require_approval",
        "enable_validation",
        "use_approval"
      ],
      "correctAnswer": 1,
      "explanation": "The require_approval parameter configures approval workflows where tool calls require validation before execution."
    },
    {
      "id": 101,
      "question": "What does the @input_guardrail decorator do?",
      "options": [
        "Creates a new agent with guardrails",
        "Marks a function as an input guardrail for agents",
        "Validates user input syntax",
        "Encrypts input data"
      ],
      "correctAnswer": 1,
      "explanation": "The @input_guardrail decorator marks an async function as an input guardrail that can be used with agents to validate incoming requests."
    },
    {
      "id": 102,
      "question": "What does the @output_guardrail decorator do?",
      "options": [
        "Formats output for display",
        "Marks a function as an output guardrail for agents",
        "Compresses output data",
        "Logs all outputs automatically"
      ],
      "correctAnswer": 1,
      "explanation": "The @output_guardrail decorator marks an async function as an output guardrail that validates agent responses before they are delivered."
    },
    {
      "id": 103,
      "question": "What type does GuardrailFunctionOutput contain for triggering execution halts?",
      "options": [
        "halt_execution",
        "stop_agent",
        "tripwire_triggered",
        "block_request"
      ],
      "correctAnswer": 2,
      "explanation": "GuardrailFunctionOutput contains a tripwire_triggered boolean that, when True, halts execution immediately."
    },
    {
      "id": 104,
      "question": "Which function from handoff_filters removes all tool calls from conversation history?",
      "options": [
        "remove_tools",
        "filter_tools",
        "remove_all_tools",
        "clear_tool_history"
      ],
      "correctAnswer": 2,
      "explanation": "The remove_all_tools function from agents.extensions.handoff_filters removes all tool calls from the conversation history during handoffs."
    },
    {
      "id": 105,
      "question": "What is the purpose of the handoff_description parameter?",
      "options": [
        "Documents the handoff for developers",
        "Provides a description to guide the LLM's handoff decision",
        "Sets the handoff timeout duration",
        "Defines handoff error messages"
      ],
      "correctAnswer": 1,
      "explanation": "The handoff_description parameter provides a description to the LLM to guide its decision on when to use that particular handoff."
    },
    {
      "id": 106,
      "question": "Which class represents a Realtime voice agent?",
      "options": ["VoiceAgent", "AudioAgent", "RealtimeAgent", "StreamAgent"],
      "correctAnswer": 2,
      "explanation": "RealtimeAgent is the class used to create agents capable of handling voice interactions in real-time."
    },
    {
      "id": 107,
      "question": "What does the RealtimeRunner class do?",
      "options": [
        "Runs agents in parallel",
        "Orchestrates realtime voice agent sessions",
        "Manages agent deployment",
        "Handles agent versioning"
      ],
      "correctAnswer": 1,
      "explanation": "RealtimeRunner orchestrates realtime voice agent sessions, managing audio input/output and session events."
    },
    {
      "id": 108,
      "question": "Which function creates a handoff for RealtimeAgent?",
      "options": [
        "create_realtime_handoff()",
        "realtime_transfer()",
        "realtime_handoff()",
        "voice_handoff()"
      ],
      "correctAnswer": 2,
      "explanation": "The realtime_handoff() function creates a handoff configuration specifically for RealtimeAgent instances."
    },
    {
      "id": 109,
      "question": "What helper function adds handoff instructions to prompts?",
      "options": [
        "add_handoff_instructions()",
        "prompt_with_handoff_instructions()",
        "include_handoff_help()",
        "enhance_prompt_handoffs()"
      ],
      "correctAnswer": 1,
      "explanation": "The prompt_with_handoff_instructions() function from agents.extensions.handoff_prompt adds handoff-related instructions to agent prompts."
    },
    {
      "id": 110,
      "question": "What class is used for managing voice pipelines?",
      "options": [
        "AudioPipeline",
        "VoiceStream",
        "VoicePipeline",
        "RealtimePipeline"
      ],
      "correctAnswer": 2,
      "explanation": "VoicePipeline is the class used for managing voice interaction pipelines with agents."
    },
    {
      "id": 111,
      "question": "What workflow class handles single agent voice interactions?",
      "options": [
        "SingleVoiceWorkflow",
        "SimpleAgentWorkflow",
        "SingleAgentVoiceWorkflow",
        "UniAgentVoice"
      ],
      "correctAnswer": 2,
      "explanation": "SingleAgentVoiceWorkflow is the workflow class designed to handle voice interactions with a single agent."
    },
    {
      "id": 112,
      "question": "What type of audio input does the SDK support by default?",
      "options": ["mp3 and wav", "pcm16 format", "opus codec", "aac format"],
      "correctAnswer": 1,
      "explanation": "The SDK supports pcm16 (16-bit PCM) audio format by default for both input and output in voice applications."
    },
    {
      "id": 113,
      "question": "Which parameter specifies the voice to use in RealtimeAgent?",
      "options": ["voice_id", "voice", "speaker", "audio_voice"],
      "correctAnswer": 1,
      "explanation": "The voice parameter in model_settings specifies which voice to use, such as 'ash', 'ballad', or 'verse'."
    },
    {
      "id": 114,
      "question": "What does 'semantic_vad' turn detection type do?",
      "options": [
        "Uses volume-based detection",
        "Uses semantic understanding for turn detection",
        "Detects voice activity duration",
        "Analyzes speech patterns"
      ],
      "correctAnswer": 1,
      "explanation": "The 'semantic_vad' turn detection type uses semantic understanding to determine when a user has finished speaking, not just silence detection."
    },
    {
      "id": 115,
      "question": "Which parameter in turn_detection enables response interruption?",
      "options": [
        "allow_interrupt",
        "interrupt_response",
        "enable_interrupts",
        "interruptible"
      ],
      "correctAnswer": 1,
      "explanation": "The interrupt_response parameter in turn_detection configuration enables or disables the ability to interrupt agent responses."
    },
    {
      "id": 116,
      "question": "What model is used for audio transcription in voice applications?",
      "options": [
        "whisper-1",
        "gpt-4o-mini-transcribe",
        "audio-transcribe",
        "realtime-transcribe"
      ],
      "correctAnswer": 1,
      "explanation": "The gpt-4o-mini-transcribe model is used for input audio transcription in realtime voice applications."
    },
    {
      "id": 117,
      "question": "Which event type indicates audio output has ended?",
      "options": [
        "audio_complete",
        "audio_finished",
        "audio_end",
        "audio_stop"
      ],
      "correctAnswer": 2,
      "explanation": "The 'audio_end' event type signals that audio output from the agent has completed."
    },
    {
      "id": 118,
      "question": "What event type indicates audio was interrupted?",
      "options": [
        "audio_stopped",
        "audio_interrupted",
        "audio_break",
        "audio_cancelled"
      ],
      "correctAnswer": 1,
      "explanation": "The 'audio_interrupted' event type signals that audio playback was interrupted, typically by user speech."
    },
    {
      "id": 119,
      "question": "Which modality setting enables both text and audio interactions?",
      "options": [
        "['text', 'audio']",
        "['audio']",
        "['multimodal']",
        "['voice', 'text']"
      ],
      "correctAnswer": 0,
      "explanation": "Setting modalities to ['text', 'audio'] enables both text and audio interactions with the agent."
    },
    {
      "id": 120,
      "question": "What does the 'require_approval' parameter value 'always' do in MCP?",
      "options": [
        "Requires password for every tool call",
        "Requires approval for every tool invocation",
        "Always logs tool calls",
        "Always validates tool parameters"
      ],
      "correctAnswer": 1,
      "explanation": "Setting require_approval to 'always' in MCP configuration requires explicit approval for every tool invocation."
    },
    {
      "id": 121,
      "question": "What callback handles MCP tool approval requests?",
      "options": [
        "on_tool_approval",
        "approval_handler",
        "on_approval_request",
        "handle_approval"
      ],
      "correctAnswer": 2,
      "explanation": "The on_approval_request callback receives MCPToolApprovalRequest objects and returns approval decisions."
    },
    {
      "id": 122,
      "question": "What type of MCP server connects to HTTP servers with low latency?",
      "options": [
        "MCPServerHttp",
        "MCPServerStreamableHttp",
        "MCPServerFastHttp",
        "MCPServerLowLatency"
      ],
      "correctAnswer": 1,
      "explanation": "MCPServerStreamableHttp connects to HTTP servers with optimized low-latency communication."
    },
    {
      "id": 123,
      "question": "Which method retrieves dynamic prompts from MCP servers?",
      "options": [
        "fetch_prompt()",
        "load_prompt()",
        "get_prompt()",
        "retrieve_prompt()"
      ],
      "correctAnswer": 2,
      "explanation": "The get_prompt() method retrieves dynamic prompts from MCP servers for context-aware instruction generation."
    },
    {
      "id": 124,
      "question": "What function creates static tool filters for MCP servers?",
      "options": [
        "filter_tools()",
        "create_tool_filter()",
        "create_static_tool_filter()",
        "setup_tool_filter()"
      ],
      "correctAnswer": 2,
      "explanation": "The create_static_tool_filter() function creates simple allow/block list filters for MCP server tools."
    },
    {
      "id": 125,
      "question": "Which parameter enables description override in @function_tool?",
      "options": [
        "custom_description",
        "override_description",
        "description_override",
        "new_description"
      ],
      "correctAnswer": 2,
      "explanation": "The description_override parameter in @function_tool allows customizing the tool's description instead of using the docstring."
    },
    {
      "id": 126,
      "question": "What parameter overrides the function name in @function_tool?",
      "options": ["tool_name", "name_override", "custom_name", "function_name"],
      "correctAnswer": 1,
      "explanation": "The name_override parameter in @function_tool allows specifying a different name than the actual function name."
    },
    {
      "id": 127,
      "question": "Which parameter disables docstring parsing in @function_tool?",
      "options": [
        "skip_docstring",
        "disable_parsing",
        "use_docstring_info",
        "parse_docstring"
      ],
      "correctAnswer": 2,
      "explanation": "Setting use_docstring_info=False in @function_tool disables automatic docstring parsing for parameter descriptions."
    },
    {
      "id": 128,
      "question": "What parameter explicitly sets the docstring parsing format?",
      "options": ["doc_format", "docstring_style", "parse_style", "doc_style"],
      "correctAnswer": 1,
      "explanation": "The docstring_style parameter explicitly sets the parsing format (Google, Sphinx, or NumPy) for function tool documentation."
    },
    {
      "id": 129,
      "question": "What class is used to manually create function tools?",
      "options": ["Tool", "CustomTool", "FunctionTool", "ManualTool"],
      "correctAnswer": 2,
      "explanation": "The FunctionTool class can be instantiated directly for manual tool creation with explicit parameters."
    },
    {
      "id": 130,
      "question": "Which parameter provides the tool execution callback in FunctionTool?",
      "options": ["callback", "execute", "on_invoke_tool", "tool_function"],
      "correctAnswer": 2,
      "explanation": "The on_invoke_tool parameter in FunctionTool provides the callback that executes when the tool is invoked."
    },
    {
      "id": 131,
      "question": "What does ToolOutputImage represent?",
      "options": [
        "An image file path",
        "A tool output containing image data with URLs",
        "An image processing tool",
        "A visualization of tool outputs"
      ],
      "correctAnswer": 1,
      "explanation": "ToolOutputImage represents a tool output containing image data, typically with URLs pointing to the images."
    },
    {
      "id": 132,
      "question": "What does ToolOutputFileContent represent?",
      "options": [
        "File system access",
        "A tool output containing file data with base64 encoding or file IDs",
        "File download links",
        "File metadata"
      ],
      "correctAnswer": 1,
      "explanation": "ToolOutputFileContent represents a tool output containing file data, either as base64-encoded content or file IDs."
    },
    {
      "id": 133,
      "question": "What session method is used in AdvancedSQLiteSession to organize conversations by turns?",
      "options": [
        "get_turns()",
        "organize_by_turns()",
        "get_conversation_by_turns()",
        "fetch_turns()"
      ],
      "correctAnswer": 2,
      "explanation": "The get_conversation_by_turns() method in AdvancedSQLiteSession organizes the conversation history by individual turns."
    },
    {
      "id": 134,
      "question": "Which AdvancedSQLiteSession method provides tool usage statistics?",
      "options": [
        "get_tool_stats()",
        "tool_analytics()",
        "get_tool_usage()",
        "analyze_tools()"
      ],
      "correctAnswer": 2,
      "explanation": "The get_tool_usage() method in AdvancedSQLiteSession provides statistics on tool usage across the conversation."
    },
    {
      "id": 135,
      "question": "What method finds turns by content in AdvancedSQLiteSession?",
      "options": [
        "search_turns()",
        "find_content()",
        "find_turns_by_content()",
        "search_conversation()"
      ],
      "correctAnswer": 2,
      "explanation": "The find_turns_by_content() method searches for turns containing specific content in AdvancedSQLiteSession."
    },
    {
      "id": 136,
      "question": "What does the ModelSettings.resolve() method do?",
      "options": [
        "Validates model configuration",
        "Merges settings with non-None override values taking precedence",
        "Resolves model name to model instance",
        "Resolves conflicts in settings"
      ],
      "correctAnswer": 1,
      "explanation": "The ModelSettings.resolve() method merges settings, with non-None values from an override parameter taking precedence."
    },
    {
      "id": 137,
      "question": "What model parameter is recommended for realtime voice interactions?",
      "options": ["gpt-4.1", "gpt-realtime", "gpt-voice", "gpt-audio"],
      "correctAnswer": 1,
      "explanation": "The 'gpt-realtime' model is specifically designed and recommended for realtime voice agent interactions."
    },
    {
      "id": 138,
      "question": "Which class represents the Chat Completions API model in the SDK?",
      "options": [
        "ChatModel",
        "CompletionsModel",
        "OpenAIChatCompletionsModel",
        "ChatCompletionModel"
      ],
      "correctAnswer": 2,
      "explanation": "OpenAIChatCompletionsModel represents the Chat Completions API for broader provider compatibility."
    },
    {
      "id": 139,
      "question": "Which class represents the Responses API model in the SDK?",
      "options": [
        "ResponseModel",
        "OpenAIResponsesModel",
        "ResponsesAPIModel",
        "APIResponseModel"
      ],
      "correctAnswer": 1,
      "explanation": "OpenAIResponsesModel represents OpenAI's Responses API, which is the recommended choice for OpenAI models."
    },
    {
      "id": 140,
      "question": "What does the 'store' parameter in ModelSettings enable?",
      "options": [
        "Local response caching",
        "Database storage",
        "Response storage for retrieval",
        "Session persistence"
      ],
      "correctAnswer": 2,
      "explanation": "The 'store' parameter in ModelSettings enables response storage for later retrieval."
    },
    {
      "id": 141,
      "question": "What does the 'top_logprobs' parameter provide?",
      "options": [
        "Top response rankings",
        "Log probability scores for tokens",
        "Confidence metrics",
        "Error probability"
      ],
      "correctAnswer": 1,
      "explanation": "The 'top_logprobs' parameter provides log probability scores for the most likely tokens at each position."
    },
    {
      "id": 142,
      "question": "What does RunItemStreamEvent provide during streaming?",
      "options": [
        "Token-level updates",
        "Item-level updates when complete items are produced",
        "Error notifications",
        "Progress percentage"
      ],
      "correctAnswer": 1,
      "explanation": "RunItemStreamEvent provides item-level updates when complete items like messages or tool calls are produced during streaming."
    },
    {
      "id": 143,
      "question": "Which property in RunResult holds ModelResponse objects from all LLM calls?",
      "options": [
        "llm_responses",
        "model_outputs",
        "raw_responses",
        "api_responses"
      ],
      "correctAnswer": 2,
      "explanation": "The raw_responses property holds ModelResponse objects from all LLM calls during execution."
    },
    {
      "id": 144,
      "question": "What does the 'current_agent' property indicate in RunResult?",
      "options": [
        "The agent currently executing",
        "The last agent in the chain (deprecated, use last_agent)",
        "The starting agent",
        "The active agent pool"
      ],
      "correctAnswer": 1,
      "explanation": "The 'current_agent' property (now deprecated in favor of last_agent) indicates which agent was last executing."
    },
    {
      "id": 145,
      "question": "What library does the SDK use to parse function docstrings?",
      "options": ["docutils", "sphinx", "griffe", "pydoc"],
      "correctAnswer": 2,
      "explanation": "The SDK uses the griffe library to parse function docstrings and extract parameter descriptions."
    },
    {
      "id": 146,
      "question": "What does the 'extra_args' parameter in ModelSettings allow?",
      "options": [
        "Additional context data",
        "Extra tools for the agent",
        "Arbitrary keyword arguments passed directly to model APIs",
        "Additional guardrails"
      ],
      "correctAnswer": 2,
      "explanation": "The 'extra_args' parameter allows passing arbitrary keyword arguments directly to model APIs for provider-specific features."
    },
    {
      "id": 147,
      "question": "Which parameter in ModelSettings accepts a Reasoning object for GPT-5?",
      "options": ["thinking", "reasoning", "analysis", "cognitive_effort"],
      "correctAnswer": 1,
      "explanation": "The 'reasoning' parameter in ModelSettings accepts a Reasoning object to configure reasoning effort for GPT-5 models."
    },
    {
      "id": 148,
      "question": "What does the 'metadata' parameter in ModelSettings provide?",
      "options": [
        "Agent metadata",
        "Provider-specific metadata for requests",
        "Tool metadata",
        "Session metadata"
      ],
      "correctAnswer": 1,
      "explanation": "The 'metadata' parameter in ModelSettings provides provider-specific metadata that can be attached to API requests."
    },
    {
      "id": 149,
      "question": "Which environment variable disables LLM input/output logging in traces?",
      "options": [
        "DISABLE_LLM_LOGGING",
        "OPENAI_AGENTS_DISABLE_LLM_IO_LOGGING",
        "NO_LLM_TRACE",
        "HIDE_LLM_DATA"
      ],
      "correctAnswer": 1,
      "explanation": "The OPENAI_AGENTS_DISABLE_LLM_IO_LOGGING environment variable disables logging of LLM inputs/outputs in traces."
    },
    {
      "id": 150,
      "question": "Which environment variable disables tool input/output logging in traces?",
      "options": [
        "NO_TOOL_LOGS",
        "DISABLE_TOOL_TRACE",
        "OPENAI_AGENTS_DISABLE_TOOL_IO_LOGGING",
        "HIDE_TOOL_DATA"
      ],
      "correctAnswer": 2,
      "explanation": "The OPENAI_AGENTS_DISABLE_TOOL_IO_LOGGING environment variable disables logging of tool inputs/outputs in traces."
    }
  ]
}
